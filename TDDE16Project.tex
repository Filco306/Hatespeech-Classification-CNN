\documentclass[twocolumn]{article}
%\documentclass{article}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{marvosym}
\makeatletter
\newcommand\footnoteref[1]{\protected@xdef\@thefnmark{\ref{#1}}\@footnotemark}
\makeatother
\graphicspath{ {Pics/}}
\title{TDDE16 Project - Hate speech classification with a convolutional neural network}
\author{Filip Cornell, filco306}

\begin{document}
\maketitle
\abstract{This article covers the topic of tweet classification, with the intent of classifying different tweets into either being offensive, using offensive language or not being offensive at all. For this, several methods to compare the results are attempted. The tweets are preprocessed and converted to vector representations using Word2Vec or TF-IDF combined with n-grams. Secondly, a convolutional neural network is trained and tried, using a grid-searching approach for different values of several hyper-parameters. As a comparison, smaller investigations of the performance of logistic regression and XGBoost are also made. The results show that a TF-IDF approach, combined with logistic regression, achieve similar results as a CNN with significantly less training time, while XGBoost achieves an almost impeccable precision specifically on hateful tweets, but quite poor results on other metrics compared to the other two methods. }
\section{Introduction}

% Introduce topic, make interesting to the reader
The internet's ability to permit everyone to speak their mind and share their knowledge opens up tremendous possibility. The amount of information possible to consume has never been greater for the ordinary person, and it has had a great impact on everyone's lives since it came to be. Social medias such as Facebook, Twitter and Instagram allow each and everyone to live a social life not only in real life, but also online. The internet is thus for most people an enriching experience, and some might even argue that it is the greatest invention of all time \cite{sleeve}. 

However, not everything the internet has brought can be considered completely positive. The possibility to speak freely also opens up for the less charming sides of the internet; harassment, hate speech and cyberbullying. This is a rising problem, and the possibility to control this by manually checking harassing posts is not only becoming increasingly difficult, but rather practically infeasible. As of November 2018, more than 500,000 posts were posted each minute on Facebook, yielding a massive amount of information \cite{zeph}. If only 1 \% of these were to be reported as offensive, this would lead to Facebook's employees having to manually check more than 2.6 billion posts each year - a huge cost. This has been a increasingly pressing issue, and the German government even threatened Facebook to fine \EUR{ 50 million} annually if they would not take serious measures tackle the issue of removing hateful and offensive posts \cite{EThomasson}. Manual reviews' inefficiency is not only problematic in terms of resources, but also speed, as the posts are left online until removed, causing the damage it was intended for. Detecting and identifying offensive and hateful posts on social media in a quick, automatic and efficient way is thus a pressing issue, and a lot of work has been done previously within the area. In this paper, we investigate how some models previously tried can be combined in a new way and see what results this might bring. The intent is to use a Convolutional Neural Network (CNN) together with the \verb|word2vec| embedding and compare this to the performance of models a TF-IDF-based approach, combined with logistic regression. The method XGBoost is also tested, but only under simple conditions. Although several papers before has used CNNs together with \verb|word2vec| to classify tweets, few seem to so far have used \verb|word2vec| as word embeddings (although it has been done for sentences before \cite{KimYoon}), but rather GloVe \cite{2018HateSD, DLNN, Gambck2017}. The paper starts with an introduction to the theory of \verb|word2vec|, CNNs and short introductions to logistic regression and XGBoost, followed by what previously has been done on tweet classification. This is followed by the method explained, and a more thorough explanation of the specific model used in this task. The results are then presented, followed by a discussion and conclusion. 

\section{Theory}

In this section, the theory behind the models and tools used are presented, as well as previous work within the field. 

\subsection{Word2vec}

In order to train a neural network to be used for natural language processing (NLP), the text must be mapped from text to vectors using a word embedding \cite{Lec}. One technique to do this is \verb|word2vec|, which uses Skip-gram and Continuous Bag-of-words (CBOW) \cite{Lec}. To summarize it shortly, the set of words are trained through a neural network, and converted into vectors of an arbitrary dimension set by the user. 

\subsection{Convolutional Neural Network (CNN)}

A popular approach when analyzing and classifying text data is to use a CNN, originally mainly used in image and sound recognition \cite{2018HateSD}. Although CNN:s can be formed in many ways, it has a basic, relatively intuitive structure. First, of all, CNN:s are not fully connected, but rather has one neurone's output going to only one other neurone in the next layer \cite{wildml}. The first layer is one with convolutional filters. On the matrix inputted, a sliding window, also known as a kernel, feature detector or filter is applied. For each operation the sliding window multiplies each value in the sliding window with the original matrix and sums these values up, creating a new output matrix, also called a feature map \cite{wildml}. These are sent to a pooling layer which reduces the size of these outputs by summarizing different subregions of the feature map. There are several methods for doing this; one can take the maximum value (max-pooling) or the average value of the sub-region \cite{dumoulin2016guide}. This basic structure can be used in several layers, along with other types of layers, but these two layers constitute the basic components of a CNN. If the mission of the task is to classify the input, the last layer usually consists of one neurone with the SoftMax function as activation function to classify into the different classes \cite{Lec}. The SoftMax function can be written as seen in (\ref{eq:softmax}), where $z_i$ denotes the output of the second last layer, and k denotes class $K$.

\begin{equation}
\label{eq:softmax}
softmax(z)[i] = \frac{e^{z_i}}{\sum_{k=1}^K e^{z_k}} \forall k \in K
\end{equation}

When using a CNN, the input size of the features is fixed. The whole sentence (in the NLP case) is thus inputted as a 2D-matrix into the neural network, with the words as rows, and their features as columns. Since, in practice, sentences can differ in length, one must pad the sentences with values to make them fit into the network. In image classification, the squares sent in usually represent images or compressed such \cite{2018HateSD}. 

\begin{figure}
  \includegraphics[width=\linewidth]{CNNGAMBACK}
  \caption{The layout of the CNN as proposed by Gamb\"ack \cite{Gambck2017}}.
  \label{fig:boat1}
\end{figure} 

Two common activation functions in the layers in between are the tanh function (equation \ref{eq:tanh}) and Rectified Linear Units (ReLU) function (equation \ref{eq:ReLU}). The tanh function, the previous norm, has been shown to have disadvantages compared to the ReLU function in terms of convergence, as the gradient does not saturate as quick. It has been shown that ReLU can converge up to six times faster than tanh \cite{Krizhevsky}.  

\begin{equation}
\label{eq:tanh}
f(x) = \frac{1}{1 + e^{-x}}
\end{equation}

\begin{equation}
\label{eq:ReLU}
f(x) = max(0,x)
\end{equation}

\subsection{XGBoost}

XGBoost is a method that recently has gained popularity on internet, being the winning method in many competitions on the site \verb|Kaggle|\footnote{\url{https://www.kaggle.com/}} \cite{XGBoostChen2016}. The method, similar to the Random Forest method, classifies through modelling a number of trees and summing up the result of the different trees. In the method, each point $\mathbf{x}$ is classified according to the function as seen in (\ref{eq:xg-pred-func}), where $\{f_1, .., f_K\} = \mathcal{F}$ is the family of trees trained through optimizing the function given in (\ref{eq:xg-obj-func}). To explain a few terms, we have that $K$ is the number of trees in $\mathcal{F}$, $T_k$ is the number of leaves for tree $f_k$ and $l(y,\hat{y})$ is the loss function for the problem, which differs depending on the problem. 

\begin{equation}
\label{eq:xg-pred-func}
\hat{y} = \phi(\mathbf{x}_i) = \sum_{k=1}^K f_k(\mathbf{x}), f_k \in \mathcal{F}
\end{equation}

\begin{equation}
\label{eq:xg-obj-func}
\mathcal{L}(\phi) = \sum_{i = 1}^n l(\hat{y}_i, y_i) + \sum_{k = 1}^K \gamma T_k + \frac{1}{2} \lambda||w_k||^2
\end{equation}

\subsection{Logistic regression}

Logistic regression is one of the most common approaches in classification. In multiclass classification, a function similar to the SoftMax function (\ref{eq:softmax}) is used, given in (\ref{eq:log-reg}). 

\begin{equation}
\label{eq:log-reg}
y_i = \frac{e^{X_i^T\beta}}{\sum_{j=1}^p e^{X_j^T\beta}}
\end{equation}

\subsection{Related work}

Many different approaches have been tried in the field of identifying and classifying hateful speech on the internet before. The first research papers on the topic were published as early as 1997 \cite{smokey}, in which a tree-based classifier managed to reach an accuracy of 88.2 \%. The data set was based 720 manually added notes on web page posts from then popular web pages. \cite{smokey} Over the years, there has been a clear trend of classifying posts on the most popular social medias, such as Twitter and Facebook. In 2016, Waseem and Hovy \cite{Waseem2016HatefulSO} apply logistic regression combined with character n-gram, achieving an F1-score of 74 \%. They are also able to extract the most indicative n-gram features in the set, indicating that features inside "muslim" or "islam" are the most indicative features for racism, while \textit{"bitc"}, \textit{"sex"} or \textit{"xist"} indicate sexual harrassment. 

On the same dataset as Waseem and Hovy \cite{Waseem2016HatefulSO}, Gamb\"ack et al. \cite{Gambck2017} applies a Convolutional Neural Network (CNN) to a set of tweets. To obtain the feature embeddings for the model, \verb|word2vec| and character n-grams were used, while word embeddings were obtained by using \verb|word2vec| and random word vectors. In the neural network, a SoftMax layer calculated the class probability. In between, a pooling layer is utilized to convert each tweet into a vector of fixed length. This pooling layer is followed by a max-pooling layer, used to capture the most important latent semantic factors in each tweet. The model resulted in a precision, at best, of 86 \% using random vectors, and an F-score of 78.29 \%, obtained through using character n-grams. 

Badjatiya P. et al. \cite{DLNN} investigates the possibility to apply three different neural network architectures on classifying tweets; CNN, Long Short-Term Memory (LSTM) and FastText. On these, word embeddings with GloVe- or random beddings are applied. \cite{DLNN} On these, gradient boosting (GBDT) is also applied as learning method. The best result is achieved with LSTM, random embeddings and GBDT, achieving an F-score of 93 \%. The GBDT makes a significant difference, seeing that the F-score of LSTM and random embeddings achieves an F-score of 84.8 \%. 

\section{Data}

To make this comparable to the recreation of previous work done, the same public datasets are used. With this, we can compare this implementation to the performance of logistic regression, based on a TF-IDF approach \cite{gaydhani}. The first two datasets are fetched from \verb|data.world|, where the tweets has been determined as offensive, hate speech or not offensive by different users.\footnote{\label{dataset1}\url{https://data.world/crowdflower/hate-speech-identification}} \footnote{\label{dataset2}\url{https://data.world/ml-research/automated-hate-speech-detection-data}} The second dataset\footnote{\label{dataset3} Available at \url{https://github.com/ZeerakW/hatespeech}} is a dataset used in three previous works \cite{gaydhani, Gambck2017,Waseem2016HatefulSO}, where the data is classified as hateful or not, but rather divided into categories 

Investigating the data further after merging the three, the two data sets have a skewedness towards neither offensive nor hateful and offensive tweets, as seen in table \ref{tab:labeldist}. 


\begin{table}[h]
\caption{Distribution of tweet classes in the entire dataset}
\label{tab:labeldist}
\begin{tabular}{|l|l|l|l|l|}
\hline
\textbf{Class/Dataset} & \textbf{1} & \textbf{2} & \textbf{3} & \textbf{$\sum$} \\ \hline
\textbf{Normal}        & 7274       & 4163       & 11501       & 22938           \\ \hline
\textbf{Offensive}     & 4836       & 19190      & 0          & 24026           \\ \hline
\textbf{Hate speech}   & 2399       & 1430       & 5290       & 9119            \\ \hline
\textbf{Total}         & 14509      & 24783      & 16791      & 56083           \\ \hline
\end{tabular}
\end{table}
%\begin{table}[h]

%\begin{tabular}{|l|l|}
%\hline
%\textbf{Class}                            & \textbf{Frequency in merged dataset} & \textbf{Frequency in merged dataset} \\ \hline
%Neither & 11437         & 11437                            \\ \hline
%Offensive    & 24026        & 24026                        \\ \hline
%Hate speech                       & 3829           & 3829                        \\ \hline
%\end{tabular}
%\end{table}

The first dataset contains 20 columns. However, only 2 are significantly interesting for the analysis. 
\begin{itemize}
\item \verb|does_this_contain_hate_speech| is classified into "The tweet uses offensive language but not hate speech", "The tweet contains hate speech"
\item \verb|tweet_text| contains the actual tweet.
\end{itemize}
 
The other columns display information such as the confidence of the labelling, based on the judgements from the manual labellers who has labelled the data, as some might have labelled some tweets differently. These would be interesting to incorporate in future work, but is left in this paper for simplification purposes and lack of time. Instead, the column \verb|does_this_contain_hate_speech| will be used. 

The second dataset contains only 7 columns, with two columns chosen for analysis in this work. 

\begin{itemize}
\item \verb|class| - the class as judged by majority of users. 
\item \verb|tweet| - a string containing the actual tweet to be analyzed. 
\end{itemize}

The data has been labelled by users on CrowdFlower, who has made judgments on whether the tweets are offensive, contains hate speech or neither. Other columns includes information such as number of votes on each class, tweet id and other information. Again, these columns would be interesting to use in further analysis, but is left for simplification. 

The third dataset only contains two columns; \verb|class| and \verb|id|, where class refers to "racism" or "sexism", indicating hate speech, or "neither", indicating a normal tweet. Just like A. Gaydhani et al \cite{gaydhani}, we consider both "racism" and "sexism" to be hatespeech, and "neither" to be a normal tweet. It is important to note that some tweets were labelled as both "neither" and either "sexism" or racism in the dataset, making it impractical to use these as neither. These were thus removed.

It is important to note that since the golden standard has been, in all the datasets, manually labeled, some tweets may have been classified incorrectly. In particular, the distinction between offensive language and hatespeech can sometimes be ambiguous. As an example, the tweet \textit{"Who can I talk to about my feelings. No homo."}\footnote{\label{tweet} The tweets given as examples does not reflect any of the author's personal beliefs or values.} has been marked as hate speech, while the tweet \textit{"}[username] \textit{proof you inbred fuck"}\footnoteref{tweet}, has been marked as offensive. It is thus important to note that it is not probable to achieve a perfect score, as these definitions of what is hate speech and what isn't has to be thoroughly defined on the training and test set; definitions that might differ when tweets originate from different datasets and investigations, as they do here. 

\subsection{Preprocessing}

First, the datasets are merged. The following preprocessings are then made (in given order). 

\begin{enumerate}
\item All characters are set to lowercase. 
\item All usernames in the tweets are removed.
\item All escaped characters, such as "\&gt" and "\&lt" are removed. 
\item All url:s are removed. 
\item The words are stemmed using the Porter Stemmer from the package \verb|nltk|.
\item Some common words are changed, such as "im" to "i'm", "lil" to "little" and so on. 
\item All stopwords are removed.
\item All non alpha-numeric character are removed. 
\end{enumerate}

Note that step 4, the stemming, will not be performed when using pre-trained word-embeddings. 

\section{Method}

To briefly describe the method for the neural network, each tweet is converted to be represented as a matrix in numerical form using the word embedding \verb|word2vec| using the package \verb|gensim|. If a tweet is shorter than the highest amount of words found in the set after preprocessing, padding is added to have the same dimensions of every tweet. The data is then split up using different seeds and then CNN is trained using 80 \%, of which 20 \% of the total amount of data is used for validation. The model is trained in 10 epochs, and is then tested on the remaining 20 \% (the test set). The metrics used to measure the performance are then calculated based on the confusion matrix retrieved from the test sets, and the weighted average, weighted by classes, of each metric will be retrieved. 

In order to perform a comparison with A. Gaydhani et al. \cite{gaydhani} and ensure that the comparison is fair, we also create their best performing model; logistic regression with a regularizer C set to 100, solved with \verb|liblinear|, using the package \verb|sklearn|. A. Gaydhani et al. uses an $n$-gram and TF-IDF approach, with $n$ ranging between 1 to 3. TF-IDF is useful since it is able to reduce the negative influence of tokens that are not really informative and does not appear frequently. Each n-gram feature is then weighted in proportion to their TFIDF value. The same approach will here be tried out, to compare the three methods. Thus, the method is here highly inspired by their previous work, available online. \footnote{Available at \url{https://github.com/adityagaydhani14/Toxic-Language-Detection-in-Online-Content/}}

XGBoost is only run in a quick fashion, as a first preliminary investigation regarding its performance. It will be run with standard settings in the package \verb|xgboost| in python, with a train and test set, showing possible results and will be evaluated on whether the preliminary results show room for improvement.

\subsection{Word embedding}

The word embedding \verb|word2vec| is applied to the whole dataset. We use two embeddings: One with pre-trained word vectors, trained on more than 2B tweets\footnote{Available at \url{https://nlp.stanford.edu/projects/glove/}}, and one which we train on the entire dataset. 

The pre-trained vectors have a dimension of 25, 50, 100 or 200 respectively. When these are used, words will not be stemmed to match the words in the pre-trained vectors. Also, we will try both removing and keeping stopwords to see whether semantics are lost. 

We test dimension of 25, 50, 100 and 200 on the word vectors and set a minimum count of 2 for a word to be included when we train the word vectors on the dataset. In other words, if a word does not exist at least twice, we will not include it as a vector, and it will be considered non-informative and the corresponding vector will be set to a 0-vector. This will yield loss of information, and one might argue that \verb|char2vec| might be useful for tweets as the number of characters is limited in a tweet to 140 characters (although it is discussed whether it is about to be doubled soon \cite{CNN}). 

\subsection{CNN}

The CNN used in this paper is quite simple and similar to the one used in Gamb\"ack et al. \cite{Gambck2017}, although slight modifications have been made. As input, we will have an $NxM$ matrix with the word embeddings, where $N$ is the maximum amount of words contained in a tweet, and $M$ is the number of dimensions for the embedded vectors. The vectors will pass into three convolutional 2-dimensional layers with convolutions of 3, 4 and 5 respectively with rectified linear units as activation functions due to its faster convergence rate \cite{Krizhevsky}. The output of these ones, are passed on to its respective max-pooling layer, which then passes it on the last classification layer with only one neurone, the Softmax layer. In figure \ref{fig:myNN}, the architecture for the network can be seen. The network architecture is the same as the architecture used by Y. Kim for sentence classification \cite{KimYoon}.

\begin{figure}
  \includegraphics[width=\linewidth]{NN-architecture}
  \caption{The network architecture used in this paper. }
  \label{fig:myNN}
\end{figure} 

During training, gradient descent with the ADAM algorithm will be used, which has shown to be computationally efficient and suitable for problems with large datasets \cite{Kingma2014AdamAM}. 

\subsection{Metrics}

To make this comparable to previous works \cite{Gambck2017, DLNN, gaydhani}, the same metrics used in those will be used here. That is, the overall accuracy, the precision, recall and the F1-score, three measures commonly used in classification problems. As we have three classes here, it should be clarified that the measures are calculated as follows. 

\begin{equation}
P_k = \frac{M_{ii}}{\sum_j M_{j,i}}
\end{equation}
\begin{equation}
R_k = \frac{M_{ii}}{\sum_j M_{i,j}}
\end{equation}
\begin{equation}
F1_k = \frac{2\cdot P_k \cdot R_k}{P_k + R_k}
\end{equation}

The average scores are then calculated by multiplying the classes' scores with their corresponding percentual representation in the test set. 
\section{Results}

The results can be seen in the tables below. Only the best results of the different settings are presented. To see all results of all runnings, please see the result files in the GitHub repo\footnote{\url{github.com}}. 

Table \ref{tab:top_results} shows the instances achieving the best overall accuracy, which were chosen for display. Table \ref{tab:explain-models} shows which model corresponds to which number in the other tables, and table \ref{tab:explan-class} shows which class corresponds to which number in other tables. Table \ref{tab:model-settings} show the different settings that was used for the models whose results are displayed. 

Tables \ref{tab:precisionss}, \ref{tab:recalls} and \ref{tab:f1s} each show the precisions, recalls and F1-scores for each of the respective class for each model chosen. 

\begin{table}[]

\begin{tabular}{|l|l|}
\hline
\textbf{Model}                        & \textbf{No.} \\ \hline
\textbf{Logistic regression, C = 100} & 1            \\ \hline
\textbf{XGBoost, pretrained vectors}   & 2            \\ \hline
\textbf{CNN pretrained vectors}       & 3            \\ \hline
\textbf{CNN, trained vectors}         & 4            \\ \hline
\end{tabular}
\caption{Table showing which model corresponding to which number in other tables.}
\label{tab:explain-models}
\end{table}


\begin{table}[]

\begin{tabular}{|l|l|}
\hline
 \textbf{Type of tweet}                                     & \textbf{Class} \\ \hline
\textbf{Hate speech}                 & 0               \\ \hline
\textbf{Offensive} & 1               \\ \hline
\textbf{Neither}                   & 2               \\ \hline
\end{tabular}
\caption{Explanation which number corresponds to which. }
\label{tab:explan-class}
\end{table}

\begin{table}[]

\begin{tabular}{|l|l|l|}
\hline
\textbf{Model}                          & \textbf{Dim. size} & $\mathbf{l_2}$ \\ \hline
\textbf{1}   & -            & -     \\ \hline
\textbf{2}     & 25           & -     \\ \hline
\textbf{3}         & 100          & 1     \\ \hline
\textbf{4} & 100          & 0.1   \\ \hline
\end{tabular}
\caption{Values for the models picked out yielding the highest accuracy. }
\label{tab:model-settings}
\end{table}


\begin{table}[]

\begin{tabular}{|l|l|l|l|l|}
\hline
\textbf{Model}                                    & \textbf{Acc.} & \textbf{Precision} & \textbf{Recall} & \textbf{F1} \\ \hline
\textbf{1} 		    & 0.867             & 0.631              & \textbf{0.747}           & 0.684             \\ \hline
\textbf{2}               & 0.716             & \textbf{0.846}              & 0.525           & 0.648             \\ \hline
\textbf{3}               & \textbf{0.868}             & 0.76                & 0.63             & \textbf{0.69}              \\ \hline
\textbf{4}           	    & 0.865             & 0.62                & 0.74             & 0.68              \\ \hline
\end{tabular}
\caption{The best result during different circumstances. }
\label{tab:top_results}
\end{table}

\begin{table}[]

\begin{tabular}{|l|l|l|l|}
\hline
\textbf{Model} & \textbf{0} & \textbf{1} & \textbf{2} \\ \hline
\textbf{1}     & 0.471      & 0.955      & \textbf{0.844}      \\ \hline
\textbf{2}     & \textbf{0.997}      & 0.752      & 0.679      \\ \hline
\textbf{3}     & 0.468      & \textbf{0.968}      & 0.834      \\ \hline
\textbf{4}     & 0.458      & 0.959      & 0.838      \\ \hline
\end{tabular}
\caption{The precisions of the different models selected for the different classes.}
\label{tab:precisionss}
\end{table}

\begin{table}[]

\begin{tabular}{|l|l|l|l|}
\hline
\textbf{Model} & \textbf{0} & \textbf{1} & \textbf{2} \\ \hline
\textbf{1}     & 0.676      & \textbf{0.867}      & 0.925      \\ \hline
\textbf{2}     & 0.143      & 0.802      & 0.854      \\ \hline
\textbf{3}     & \textbf{0.71}       & 0.855      & \textbf{0.945}      \\ \hline
\textbf{4}     & 0.676      & 0.863      & 0.926      \\ \hline
\end{tabular}
\caption{The recalls of the different models selected for the different classes.}
\label{tab:recalls}
\end{table}

\begin{table}[]

\begin{tabular}{|l|l|l|l|}
\hline
\textbf{Model} & \textbf{0} & \textbf{1} & \textbf{2} \\ \hline
\textbf{1}     & \textbf{0.556}      & \textbf{0.91}       & 0.883      \\ \hline
\textbf{2}     & 0.250 & 0.777 & 0.756 \\ \hline
\textbf{3}     & 0.564      & 0.908      & \textbf{0.886}      \\ \hline
\textbf{4}     & 0.546 & 0.908 & 0.88       \\ \hline
\end{tabular}
\caption{The F1-scores of the different models selected for the different classes.}
\label{tab:f1s}
\end{table}


\pagebreak


\section{Discussion}

On an overall level, the overall results, seen in \ref{tab:top_results} are fairly promising. However, none of the models seem to match state-of-the-art performance on metrics such as F1-score, precision or recall, when comparing to Badjatiya P. et al. \cite{DLNN} or Gamb\"ack et al. \cite{Gambck2017}. This might be caused by the difference in data sets used, but also further adjustments to the models made by Badjatiya et al. not made during this investigation. It is however noteworthy that when running the instances of the CNN, the metric optimized by the model was the accuracy. Further investigations should thus focus on rather optimizing the precision, recall or F1-score to obtain better results on these metrics, something which is possible through simple modifications of the code. Thus, it is not excluded that better results can be obtained with the right modifications. 

What is significant is that the precisions and recalls vary greatly between the classes for all models. Even with oversampling, the precision for the hate speech class does not exceed 0.71 for any CNN instance, and the maximum recall value achieved by any CNN instance is 0.73, while both of these metrics perform much better, at least above 0.83, on the two other classes. This shows how the CNN is sensitive to an imbalanced data set, and should be mitigated. However, although logistic regression has been shown empirically to not be as sensitive as neural networks imbalanced data sets, it does not perform significantly better than any of the CNN instances on any of the measures. This, combined with the fact that oversampling did not help to improve the results, indicate that further modifications not identified in this work should be made. However, the significant difference in training time of the two methods puts logistic regression in favour to further investigate, and see if further improvements could be made to increase the metrics examined. However, the fact that the CNN can be easily modified to rather focus on obtaining a higher precision or recall opens up for further customizing the model to obtain the practical results one wishes for. 

As seen in table \ref{tab:precisionss}, XGBoost has a precision near 1 on hateful tweets. This indicates significant differences in the properties and advantages of the different models, as XGBoost tends to favour precision. Although its recall is very poor, this can possibly be adjusted through further adjustments and investigations. As mentioned, XGBoost was only run in a simple fashion as an initial investigation with no tuning over different parameters. Possible adjustments might lead to more balanced results between recall and precision, yielding a better F1-score. Out of a practical perspective, a model favouring recall over precision is probably to be preferred, as one would like to automatically catch all \textit{possibly} hateful tweets to then be manually examined, rather than missing some hateful tweets and being able to automatically classify only a small portion of all the hateful tweets. 

As seen in table (\ref{tab:model-settings}), the most appropriate dimension size of the \verb|word2vec|-vectors were 100 dimensions. All other dimensional sizes did however perform fairly well; none had an accuracy of less than 7 \% below the best accuracy achieved. This indicates that while the choice of dimensions does matter, it is not of utmost importance. 

Table (\ref{tab:f1s}), showing the F1-scores, show that the logistic regression and the CNN:s with pretrained and trained word vectors are more or less equal in results. XGBoost differs, mainly due to its poor recall for class 0, but also worse precision for classes 1 and 2 (offensive and normal tweets). 

\section{Conclusion}

In this investigation, logistic regression with a TF-IDF approach to process the texts was compared with a simple version of XGBoost and a gridsearch of the optimal values for a CNN using Word2Vec. The results show that the logistic regression model and CNN model are relatively equal in results when one aims to maximize the accuracy, favouring logistic regression due to its significantly quicker training time. The XGBoost method shows excellent results for specifically achieving a high precision on the hateful tweets, which opens up possibilities for this to be used for automatic removal of hateful tweets, although its recall performed poorly. 

Although the TF-IDF based approach combined with logistic regression had a significantly shorter training time, the possibility of easily customizing the CNN's results depending on which metric one wishes to optimize indicates that further investigations should be made to see if the recall could be increased to open up for manual investigations of the tweets classified as hateful, to reduce the time spent on finding hateful tweets. However, in the end, the optimal scenario would be to find a model with an excellent F1-score, specifically for the hateful tweets. This is however a hard challenge; the simple decision of what is hateful and offensive could often prove ambiguous, as seen in the data. Before a perfect classification model could be achieved, a perfect definition of what is a hateful, offensive and non-offensive tweet is would have to be created, which probably is harder than building a classification model. 

\section{References}
\bibliographystyle{plain}
\bibliography{references}

\end{document}